{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-11-14T04:22:40.163015Z","iopub.status.busy":"2022-11-14T04:22:40.162528Z","iopub.status.idle":"2022-11-14T04:22:46.392242Z","shell.execute_reply":"2022-11-14T04:22:46.391178Z","shell.execute_reply.started":"2022-11-14T04:22:40.162936Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from keras import Sequential\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import * \n","from tensorflow.keras.preprocessing import image"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-11-14T04:22:53.518698Z","iopub.status.busy":"2022-11-14T04:22:53.51783Z","iopub.status.idle":"2022-11-14T04:22:53.524914Z","shell.execute_reply":"2022-11-14T04:22:53.523932Z","shell.execute_reply.started":"2022-11-14T04:22:53.518655Z"},"trusted":true},"outputs":[],"source":["train_path= 'dataset/train/'\n","test_path='dataset/val/'"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-11-14T04:22:55.416983Z","iopub.status.busy":"2022-11-14T04:22:55.416611Z","iopub.status.idle":"2022-11-14T04:22:55.423471Z","shell.execute_reply":"2022-11-14T04:22:55.422124Z","shell.execute_reply.started":"2022-11-14T04:22:55.416953Z"},"trusted":true},"outputs":[],"source":["train_datagen = image.ImageDataGenerator(\n","    rotation_range=15,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest',\n","    width_shift_range=0.1,\n","    height_shift_range=0.1\n",")\n","val_datagen= image.ImageDataGenerator(    rotation_range=15,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest',\n","    width_shift_range=0.1,\n","    height_shift_range=0.1)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-11-14T04:22:55.716926Z","iopub.status.busy":"2022-11-14T04:22:55.716558Z","iopub.status.idle":"2022-11-14T04:22:59.252953Z","shell.execute_reply":"2022-11-14T04:22:59.251844Z","shell.execute_reply.started":"2022-11-14T04:22:55.716892Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 8863 images belonging to 2 classes.\n","Found 600 images belonging to 2 classes.\n"]}],"source":["train_generator = train_datagen.flow_from_directory(\n","    train_path,\n","    target_size = (224,224),\n","    batch_size = 4,\n","    class_mode = 'binary')\n","validation_generator = val_datagen.flow_from_directory(\n","    test_path,\n","    target_size = (224,224),\n","    batch_size = 4,\n","    shuffle=True,\n","    class_mode = 'binary')"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-11-14T04:36:02.223324Z","iopub.status.busy":"2022-11-14T04:36:02.222967Z","iopub.status.idle":"2022-11-14T04:36:06.155199Z","shell.execute_reply":"2022-11-14T04:36:06.154171Z","shell.execute_reply.started":"2022-11-14T04:36:02.223296Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," efficientnetb3 (Functional)  (None, 7, 7, 1536)       10783535  \n","                                                                 \n"," gaussian_noise (GaussianNoi  (None, 7, 7, 1536)       0         \n"," se)                                                             \n","                                                                 \n"," global_average_pooling2d (G  (None, 1536)             0         \n"," lobalAveragePooling2D)                                          \n","                                                                 \n"," dense (Dense)               (None, 512)               786944    \n","                                                                 \n"," batch_normalization (BatchN  (None, 512)              2048      \n"," ormalization)                                                   \n","                                                                 \n"," gaussian_noise_1 (GaussianN  (None, 512)              0         \n"," oise)                                                           \n","                                                                 \n"," dropout (Dropout)           (None, 512)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 513       \n","                                                                 \n","=================================================================\n","Total params: 11,573,040\n","Trainable params: 788,481\n","Non-trainable params: 10,784,559\n","_________________________________________________________________\n"]}],"source":["base_model = tf.keras.applications.EfficientNetB3(weights='imagenet', input_shape=(224,224,3), include_top=False)\n","\n","for layer in base_model.layers:\n","    layer.trainable=False\n","model = Sequential()\n","model.add(base_model)\n","model.add(GaussianNoise(0.25))\n","model.add(GlobalAveragePooling2D())\n","model.add(Dense(512,activation='relu'))\n","model.add(BatchNormalization())\n","model.add(GaussianNoise(0.25))\n","model.add(Dropout(0.25))\n","model.add(Dense(1, activation='sigmoid'))\n","model.summary()"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-11-14T04:36:10.55863Z","iopub.status.busy":"2022-11-14T04:36:10.557851Z","iopub.status.idle":"2022-11-14T04:36:10.574264Z","shell.execute_reply":"2022-11-14T04:36:10.572679Z","shell.execute_reply.started":"2022-11-14T04:36:10.558593Z"},"trusted":true},"outputs":[],"source":["model.compile(loss='binary_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy','Precision','Recall','AUC'])"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-11-14T04:36:27.977538Z","iopub.status.busy":"2022-11-14T04:36:27.977171Z","iopub.status.idle":"2022-11-14T04:39:38.861095Z","shell.execute_reply":"2022-11-14T04:39:38.860063Z","shell.execute_reply.started":"2022-11-14T04:36:27.977508Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","50/50 [==============================] - ETA: 0s - loss: 0.7396 - accuracy: 0.6600 - precision: 0.6277 - recall: 0.6413 - auc: 0.6935\n","Epoch 1: val_accuracy improved from -inf to 0.60167, saving model to best_model.pth\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 131). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: best_model.pth\\assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: best_model.pth\\assets\n"]},{"ename":"TypeError","evalue":"Unable to serialize [2.0896919 2.1128857 2.1081853] to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32md:\\Important\\Education\\Bachelor_of_Engineering\\Computer_Science_Engineering\\Third_Year\\Fifth_Semester\\Project_Expo\\Radial_Fracture-CNN.ipynb Cell 8\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Important/Education/Bachelor_of_Engineering/Computer_Science_Engineering/Third_Year/Fifth_Semester/Project_Expo/Radial_Fracture-CNN.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m checkpoint \u001b[39m=\u001b[39m ModelCheckpoint(filepath, monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Important/Education/Bachelor_of_Engineering/Computer_Science_Engineering/Third_Year/Fifth_Semester/Project_Expo/Radial_Fracture-CNN.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m call\u001b[39m=\u001b[39m[checkpoint,lrp]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Important/Education/Bachelor_of_Engineering/Computer_Science_Engineering/Third_Year/Fifth_Semester/Project_Expo/Radial_Fracture-CNN.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Important/Education/Bachelor_of_Engineering/Computer_Science_Engineering/Third_Year/Fifth_Semester/Project_Expo/Radial_Fracture-CNN.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     train_generator,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Important/Education/Bachelor_of_Engineering/Computer_Science_Engineering/Third_Year/Fifth_Semester/Project_Expo/Radial_Fracture-CNN.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Important/Education/Bachelor_of_Engineering/Computer_Science_Engineering/Third_Year/Fifth_Semester/Project_Expo/Radial_Fracture-CNN.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_generator,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Important/Education/Bachelor_of_Engineering/Computer_Science_Engineering/Third_Year/Fifth_Semester/Project_Expo/Radial_Fracture-CNN.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49m \u001b[39m50\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Important/Education/Bachelor_of_Engineering/Computer_Science_Engineering/Third_Year/Fifth_Semester/Project_Expo/Radial_Fracture-CNN.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcall\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Important/Education/Bachelor_of_Engineering/Computer_Science_Engineering/Third_Year/Fifth_Semester/Project_Expo/Radial_Fracture-CNN.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\Kaliraj\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n","File \u001b[1;32mc:\\Users\\Kaliraj\\AppData\\Local\\Programs\\Python\\Python38\\lib\\json\\encoder.py:199\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[39mreturn\u001b[39;00m encode_basestring(o)\n\u001b[0;32m    196\u001b[0m \u001b[39m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[39m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[1;32m--> 199\u001b[0m chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterencode(o, _one_shot\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    200\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(chunks, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[0;32m    201\u001b[0m     chunks \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(chunks)\n","File \u001b[1;32mc:\\Users\\Kaliraj\\AppData\\Local\\Programs\\Python\\Python38\\lib\\json\\encoder.py:257\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[1;34m(self, o, _one_shot)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    253\u001b[0m     _iterencode \u001b[39m=\u001b[39m _make_iterencode(\n\u001b[0;32m    254\u001b[0m         markers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault, _encoder, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindent, floatstr,\n\u001b[0;32m    255\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkey_separator, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem_separator, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msort_keys,\n\u001b[0;32m    256\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mskipkeys, _one_shot)\n\u001b[1;32m--> 257\u001b[0m \u001b[39mreturn\u001b[39;00m _iterencode(o, \u001b[39m0\u001b[39;49m)\n","\u001b[1;31mTypeError\u001b[0m: Unable to serialize [2.0896919 2.1128857 2.1081853] to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>."]}],"source":["from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n","lrp=ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=2)\n","filepath='best_model.pth'\n","checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n","call=[checkpoint,lrp]\n","history = model.fit(\n","    train_generator,\n","    epochs=10,\n","    validation_data=validation_generator,\n","    steps_per_epoch= 50,\n","    callbacks=call\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-14T04:45:09.434045Z","iopub.status.busy":"2022-11-14T04:45:09.433661Z","iopub.status.idle":"2022-11-14T04:47:36.508122Z","shell.execute_reply":"2022-11-14T04:47:36.507026Z","shell.execute_reply.started":"2022-11-14T04:45:09.434013Z"},"trusted":true},"outputs":[],"source":["model.evaluate(train_generator)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-14T04:47:51.954614Z","iopub.status.busy":"2022-11-14T04:47:51.954246Z","iopub.status.idle":"2022-11-14T04:48:02.283911Z","shell.execute_reply":"2022-11-14T04:48:02.282847Z","shell.execute_reply.started":"2022-11-14T04:47:51.954582Z"},"trusted":true},"outputs":[],"source":["model.evaluate(validation_generator)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from tensorflow.keras.utils import load_img, img_to_array\n","img = load_img('dataset/val/not fractured/2-rotated1.jpg',target_size=(224,224))\n","imag = img_to_array(img)\n","imaga = np.expand_dims(imag,axis=0) \n","ypred = model.predict(imaga)\n","print(ypred)\n","a=ypred[0]\n","if a<0.5:\n","      op=\"Fracture\"   \n","else:\n","      op=\"Normal\"\n","plt.imshow(img)\n","print(\"THE UPLOADED X-RAY IMAGE IS: \"+str(op))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"nbformat":4,"nbformat_minor":4}
